# ML Mastery Batch Normalization

Aqui estudaremos como acelerar o processo de treinamento de nossa rede neural de aprendizado profundo usando a Batch normalization (normalização em lote).

A normalização em lote, ou batchnorm para abreviar, é proposta como uma técnica para ajudar a coordenar a atualização de várias camadas no modelo.
